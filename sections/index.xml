<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Sections on Insights for Action</title><link>/sections/</link><description>Recent content in Sections on Insights for Action</description><generator>Hugo</generator><language>en</language><managingEditor>paul@insightsforaction.uk (Paul Hewson)</managingEditor><webMaster>paul@insightsforaction.uk (Paul Hewson)</webMaster><atom:link href="/sections/index.xml" rel="self" type="application/rss+xml"/><item><title>Actionable Insight</title><link>/sections/insight/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>paul@insightsforaction.uk (Paul Hewson)</author><guid>/sections/insight/</guid><description>&lt;p>&lt;img src="/images/branding/logo.png#centre" alt="Insight for Action logo">&lt;/p>
&lt;p>Nowadays, we rarely ask the question &amp;ldquo;do we have data&amp;rdquo;. Often we have &lt;strong>lots&lt;/strong> of data and the first barrier we hit may force us to instead ask &amp;ldquo;do we have the &lt;strong>right&lt;/strong> data?&amp;rdquo; Even when the answer to this question is &lt;strong>NO&lt;/strong>, we often need to be able to do the best we can with the available data. It has become so easy to collect vast quantities of electronic data as a byproduct of other processes that we expect data to be on tap and free. It is still the case that well designed and specific data collection can yield better answers than a &amp;ldquo;free&amp;rdquo; data source. However, we still need to be able to combine insights from different data sources; some purposefully collected, some byproducts of another process. This blog will illustrate the caveats and cautions we have to take in order to learn from data.&lt;/p></description></item><item><title>Modern Data Science</title><link>/sections/modern/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><author>paul@insightsforaction.uk (Paul Hewson)</author><guid>/sections/modern/</guid><description>&lt;p>There are two key things to say about modern Data Science.&lt;/p>
&lt;h3 id="continuous-improvement--continuous-delivery">Continuous Improvement / Continuous Delivery&lt;/h3>
&lt;p>The first concerns &amp;ldquo;Continous Integration/Continuous Delivery&amp;rdquo; (CI/CD); a modern software development practice. The advantages of scripted analyses (reproducibility, testing, auditability) are well established; it&amp;rsquo;s a small leap to seeing these scripts as simple pieces of software and realising they need their entire architecture specified and tested continuously. Indeed I have published in &lt;a href="https://link.springer.com/article/10.1007/s10479-013-1475-4">Annals of Operations Research&lt;/a> on the pitfalls of spreadsheets for data analysis. Using CI/CD in software projects is a well established way of minimizing technical debt; in data science there is a human tendency to focus on producing beautifully crafted scripts that work well today, without considering all the various stages of analysis of software dependency. One example, we need to update software versions regularly (bugfixes and needed feature enhancements).&lt;/p></description></item></channel></rss>