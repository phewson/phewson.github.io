<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1"><title>Data Privacy; Disclosure control and differential privacy - Insights for Action</title>
<meta name=description content="The role of disclosure control and differential privacy in data privacy and statistical analysis"><meta name=author content="Paul Hewson"><script type=application/ld+json>{"@context":"http://schema.org","@type":"WebSite","name":"Insights for Action","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Organization","name":"","url":"\/"}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"item":{"@id":"\/","name":"home"}},{"@type":"ListItem","position":3,"item":{"@id":"\/posts\/2021-08-05-disclosure_control_privacy\/","name":"Data privacy; disclosure control and differential privacy"}}]}</script><script type=application/ld+json>{"@context":"http://schema.org","@type":"Article","author":{"name":"map[authorinfo:Currently Senior Lecturer in Mathematics and Statistics at the University of Exeter email:paul@insightsforaction.uk github:https:\/\/github.com\/phewson linkedin:https:\/\/www.linkedin.com\/in\/pahewson\/ mastodon:https:\/\/datasci.social\/@texhewson name:Paul Hewson website:https:\/\/insightsforaction.uk youtube:@PaulHewsonPhD]"},"headline":"Data Privacy; Disclosure control and differential privacy","description":"The role of disclosure control and differential privacy in data privacy and statistical analysis","inLanguage":"en","wordCount":1522,"datePublished":"2021-08-04T20:34:51","dateModified":"2021-08-04T20:34:51","image":"\/","keywords":["Disclosure-control, Differential-privacy, Data-ethics-and-governance, Public-data"],"mainEntityOfPage":"\/posts\/2021-08-05-disclosure_control_privacy\/","publisher":{"@type":"Organization","name":"\/","logo":{"@type":"ImageObject","url":"\/","height":60,"width":60}}}</script><meta property="og:title" content="Data Privacy; Disclosure control and differential privacy"><meta property="og:description" content="The role of disclosure control and differential privacy in data privacy and statistical analysis"><meta property="og:url" content="/posts/2021-08-05-disclosure_control_privacy/"><meta property="og:type" content="website"><meta property="og:site_name" content="Insights for Action"><link rel=apple-touch-icon sizes=180x180 href=/favicon/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon/favicon-16x16.png><meta name=generator content="Hugo 0.141.0"><link rel=alternate href=/index.xml type=application/rss+xml title="Insights for Action"><script src=/js/dark-mode.js></script><script src=/vendor/lunr/lunr.min.js></script><script src=/js/lunr-search.js data-index=/search.json></script><link rel=stylesheet href=/style.min.css><link href=/vendor/glightbox/css/glightbox.min.css rel=stylesheet><script src=/vendor/glightbox/js/glightbox.min.js></script></head><body><div class="container fixed-top mw-100"><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-10 col-xl-10"><nav class="navbar navbar-expand-lg navbar-light fixed-top p-0"><div class=container><a class="navbar-brand fw-bold" href=/>Insights for Action</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarNav aria-controls=navbarNav aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse justify-content-end" id=navbarNav><ul class="navbar-nav mb-2 mb-lg-0 align-items-baseline"><li class=nav-item><a class=nav-link title="Data Stories" href=/>Data Stories</a></li><li class=nav-item><a class=nav-link title=Kayaking href=/kayaking/>Kayaking</a></li><li class=nav-item><a class=nav-link title="Tech Musings" href=/tech/>Tech Musings</a></li><li class=nav-item><a class=nav-link title=Tags href=/tags/>Tags</a></li><li class=nav-item><a class=nav-link title=About href=/about/>About</a></li><li class="nav-item dropdown"><button class="p-1 bg-light rounded dropdown-toggle border" data-bs-toggle=dropdown aria-expanded=false>
en</button><ul class=dropdown-menu><li><a class="dropdown-item active" aria-current=page href=/posts/2021-08-05-disclosure_control_privacy/>English</a></li></ul></li><li class="nav-item nav-link"><a id=dark-mode-toggle class="bi bi-moon-stars" role=button></a></li><li class="nav-item search-item"><form id=search class=search role=search><label for=search-input class="bi bi-search search-icon"></label>
<input type=search id=search-input class=search-input></form></li></ul><template id=search-heading hidden data-results-none data-results-one data-results-many><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><h1 id=search-title class=search-title></h1></div></div></template><template id=search-result hidden><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><article class="content post"><h2><a class=summary-title-link></a></h2><div class=post-entry></div><div class=read-more-section><h6 class="text-muted link-underline"><a class=read-more-link>Read More
<i class="bi bi-arrow-right"></i></a></h6></div></article></div></div></template></div></div></nav></div></div></div><header class=header-section><div class="intro-header no-img mt-10"><div class=container><div class="row justify-content-center"><div class="col-sm-12 col-md-12 col-lg-12 col-xl-12"><div class=posts-heading><h1 class="fw-semibold display-5 lh-1 mb-3">Data Privacy; Disclosure control and differential privacy</h1></div></div></div></div></div></header><div class=container role=main><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><div class="card-image card-image-blog p-0"></div></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><article role=main class=blog-post><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><p><img src=/en/posts/2021-08-05-disclosure_control_privacy/pexels-pixabay-39584.jpg alt="Data lock and chain">
<em>Photo by Pixabay from Pexels</em></p><p>I&rsquo;ve been reading a lot about how <strong>Differential Privacy</strong> is the answer to all our privacy concerns. However, having probed the methodology in detail, I&rsquo;m not so sure. Indeed, I think we have a silo problem. Differential Privacy has been developed in a Computer Science framework as a means of balancing the need for altering data to meet privacy requirements with the need to maintain data close enough to their raw state to yield meaningful answers. But I&rsquo;m not convinced people working with tools from canonical Computer Science ask the same questions as people working from canonical Statistical Science (I include sociologists, demographers, public health researchers within this latter framework). So I&rsquo;ve written this post as a first step to understanding the broader Differential Privacy framework. I can understand specific results for specific methods; but I just don&rsquo;t see that Differential Privacy magically solves all possible trade-offs between preserving individual privacy and making data available to researchers which can answer their questions with sufficient accuracy.</p><p>I also have my own bias, which is that we should avoid bias. That&rsquo;s a slightly strange statement from a Bayesian Statistician who is stereo-typically willing to accept a little bias if the estimation method has better mean square error (for want of a better metric). In this case, what I mean by bias is that we don&rsquo;t want to use privacy methods that <strong>systematically underestimate the strength of relationship between variables</strong>. I fully respect the need to preserve individual privacy. Indeed, I look to governments and census bureaus to lead the way in showing how you can respect privacy and obtain insight from data. Nevertheless, I would prefer we used methods which were able to account for any uncertainty we have introduced into an analysis as a result of using a privacy respecting stage in our data pipeline..</p><p>I have delivered many consulting problems where I needed to work with publicly available data that had been subject to some disclosure control mechanism. A well established weakness of many applications of statistical methods is that they only provide uncertainty estimates (confidence / credible intervals) for <strong>aleatory uncertainty</strong>; that part of our uncertainty due to random sampling. <strong>Epistemic uncertainty</strong> such as non-response bias, model mis-specification or <strong>data that have been permuted for privacy reasons</strong> is simply ignored. I have never liked the fact that disclosure control methods introduce uncertainty in a way that cannot be acknowledged in the results of an analysis. To give a concrete example, you don&rsquo;t want to do an analysis comparing a policy intervention with a baseline and report that the credible intervals for the effect of the intervention did not overlap if you knew that adding in an allowance for various sources of epistemic uncertainty widened the intervals such that they did overlap. You end up recommending policies that are not effective.</p><p>As it happens, most of my engagement with this subject has been in trying to reconstitute multi-way census tables. I know full well this is impossible (because the disclosure control methods make it so). Equally I know there are methods such as <a href=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC17264/>Bonferroni bounds</a> which let you put bounds on the range of count values that any given cell could take (strictly speaking these should be called Bonferroni-Fréchet-Hoeffding bounds as several workers discovered them simultaneously). But for myself, I&rsquo;ve always preferred the idea of releasing multiple versions of a table which allow propagation of the uncertainty after you&rsquo;ve applied a method such as iterative proportional fitting to reconstitute the full table based on the released micro-data and local census tables.</p><p>The long and the short of this problem is that there is a trade-off between protecting individual privacy and preserving the statistical accuracy for researchers. The more noise you add, the less likely that individuals can have their data identified. But the more noise you add, the further the data are from the &ldquo;truth&rdquo;. The big problem for working with tables is that permuting the cell contents may <em>weaken</em> the observed relationship between variables.</p><p>There are two &ldquo;classical&rdquo; methods for ensuring data privacy. The first is cell suppression. You never allow any query if the conditions of that query are met by only one record in the database. The problem with this rule is that you can attack it using set differencing. I can&rsquo;t get a cross-tabulation of age, sex and commute method because there is a single female cyclist in a given age band in a given census output area. So I query how many female cyclists there are in that output area for all ages, and then for all ages excluding the one of interest and can see there is a single respondent. A popular alternative is data swapping; a subset of the data is taken and within this records are swapped with that of similar records. So I may think I have identified an output area with a single female cyclists of a given age band; the truth is I don&rsquo;t know whether she was swapped there from another area. At a higher level, the numbers are consistent, but as my querying becomes more granular the noise may be a bigger component of the table. There is a well established R package which implements classical disclosure control methodology <a href=https://www.jstatsoft.org/article/view/v067i04>sdc</a>. The ONS provides extensive guidance on how to apply <a href=https://www.ons.gov.uk/methodology/methodologytopicsandstatisticalconcepts/disclosurecontrol>disclosure control methods</a> and a common method was chosen for 2011 for all <a href=https://www.ons.gov.uk/census/2011census/howourcensusworks/howwetookthe2011census/howweplannedfordatadelivery/protectingconfidentialitywithstatisticaldisclosurecontrol>UK census authorities</a>.</p><p>Anyway, life moves on and of course state of the art in ensuring data privacy when releasing data nowadays seems to be Differential Privacy. <a href=https://cran.r-project.org/web/packages/diffpriv/index.html>DiffPriv</a> provides differential privacy methods in to complement the more traditional disclosure control methods. Despite being the current fashion, it is an old and widely used technique. Just add some random noise. For researchers with simple univariate analyses to conduct, the Data Privacy modified data should have an average value should be close to the true value. Unlike data swapping however, noise is typically added to the final value rather than to the raw data. Also, unlike traditional disclosure control methods, queries are run repeatedly on the source data and different perturbations may be applied each time. With more conventional disclosure control, a perturbed set of results is created once and then released to the public. Moreover, under Differential Privacy, a perturbation method must be developed for every statistical method. With more traditional disclosure control, once the data had been perturbed they can be used for any kind of analysis.</p><h2 id=differential-privacy-is-defined-in-probabilistic-terms>Differential Privacy is defined in probabilistic terms:</h2><ul><li>Consider two datasets \(DF\) and \(DF&rsquo;\)</li><li>Both have the same variables \(j=1, \ldots, P\) and the same number of row \(i=1, \ldots, n\)</li><li>However, they differ in the contents of one row</li><li>Denote the response to applying a query \(Q\) to these datasets as \(Q(DF)\) and \(Q(DF&rsquo;)\).</li></ul><p>For any set \(\Omega\) that can be created by applying \(Q()\) to any such dataset,</p><p>$$P(Q(DF) \in \Omega) &lt; \exp(\epsilon) \times P(Q(DF&rsquo;) \in \Omega)$$</p><p>The smaller we set \(\epsilon\) the more we assure privacy.</p><p>An example (taken from the excellent <a href=https://privacytools.seas.harvard.edu/files/privacytools/files/pedagogical-document-dp_new.pdf>Differential Privacy: A Primer for a non-Technical Audience</a> is as follows:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback><span style=display:flex><span>Consider computing an estimate of the number of HIV-positive individuals in a sample, where the sample contains $n= 10,000$ individuals of whom $m= 38$ are HIV-positive.  In a differentially private version of the computation, random noise $Y$ is introduced into the count so as to hide the contribution of a single individual.   That is, the result of the computation would be
</span></span><span style=display:flex><span>$m′= m+Y= 38 +Y$ instead of $m= 38$.
</span></span></code></pre></div><p>To me, it seems we have several remaining problems. These include the use of Laplacian errors to perturb count values. This means if your Laplacian noise makes a count negative you then need to set that equal to zero which adds an additional step and hence further noise. But I also note that we are talking about univariate analyses. I&rsquo;ve been almost entirely concerned about the associations between categorical variables (using a variety of log-Linear, graphical models or recently graphical causal inference models to provide analytic output). This kind of noise addition is going to <strong>reduce the apparent association</strong> between categorical variables in published tables. Given my interests tend to be on the lines of &ldquo;what is the association between ethnicity and Covid-19 mortality, conditional on a number of important other factors such as age, sex, occupation and so on&rdquo;, I really don&rsquo;t want to be given data subject to a Differential Privacy technique which reduces the strength of that association. And ideally, I would like to be able to estimate the epistemic uncertainty associated with the data privacy perturbations. We accept random sampling in statistics; and quantify the associated errors. Why aren&rsquo;t we looking for privacy preserving methods that help us quantify the uncertainty we&rsquo;ve added to an analysis in doing this?</p><p>In summary, I still think I like the idea of being supplied multiple tables of results in a way that preserves privacy but lets me quantify the uncertainty associated with these kinds of procedures. This gets talked about constantly in statistical circles. I have to say, I&rsquo;m not convinced Differential Privacy is the last word on the matter.</p></article></div></div><div class=row><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1"><hr class=m-0></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-2"><div class=blog-tags><a href=/tags/disclosure-control/>Disclosure-control</a>
<a href=/tags/differential-privacy/>Differential-privacy</a>
<a href=/tags/data-ethics-and-governance/>Data-ethics-and-governance</a>
<a href=/tags/public-data/>Public-data</a></div></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"><section id=social-share><div class="list-inline footer-links"><div><p>Use the share button below if you liked it.</p></div><div class=share-box aria-hidden=true><ul class=share><li><a href="//www.facebook.com/sharer/sharer.php?u=%2fposts%2f2021-08-05-disclosure_control_privacy%2f" target=_blank title="Share on Facebook"><svg width="16" height="16" class="bi bi-facebook" viewBox="0 0 16 16"><path d="M16 8.049c0-4.446-3.582-8.05-8-8.05C3.58.0-.002 3.603-.002 8.05c0 4.017 2.926 7.347 6.75 7.951v-5.625h-2.03V8.05H6.75V6.275c0-2.017 1.195-3.131 3.022-3.131.876.0 1.791.157 1.791.157v1.98h-1.009c-.993.0-1.303.621-1.303 1.258v1.51h2.218l-.354 2.326H9.25V16c3.824-.604 6.75-3.934 6.75-7.951z"/></svg></a></li><li><a href="//twitter.com/share?url=%2fposts%2f2021-08-05-disclosure_control_privacy%2f&amp;text=Data%20Privacy%3b%20Disclosure%20control%20and%20differential%20privacy&amp;via=map%5bauthorinfo%3aCurrently%20Senior%20Lecturer%20in%20Mathematics%20and%20Statistics%20at%20the%20University%20of%20Exeter%20email%3apaul%40insightsforaction.uk%20github%3ahttps%3a%2f%2fgithub.com%2fphewson%20linkedin%3ahttps%3a%2f%2fwww.linkedin.com%2fin%2fpahewson%2f%20mastodon%3ahttps%3a%2f%2fdatasci.social%2f%40texhewson%20name%3aPaul%20Hewson%20website%3ahttps%3a%2f%2finsightsforaction.uk%20youtube%3a%40PaulHewsonPhD%5d" target=_blank title="Share on Twitter"><svg width="16" height="16" class="bi bi-twitter-x" viewBox="0 0 16 16"><path d="M12.6.75h2.454l-5.36 6.142L16 15.25h-4.937l-3.867-5.07-4.425 5.07H.316l5.733-6.57L0 .75h5.063l3.495 4.633L12.601.75zm-.86 13.028h1.36L4.323 2.145H2.865l8.875 11.633z"/></svg></a></li><li><a href="https://www.linkedin.com/shareArticle?mini=true&amp;url=%2fposts%2f2021-08-05-disclosure_control_privacy%2f&amp;title=Data%20Privacy%3b%20Disclosure%20control%20and%20differential%20privacy" target=_blank title="Share on LinkedIn"><svg width="16" height="16" class="bi bi-linkedin" viewBox="0 0 16 16"><path d="M0 1.146C0 .513.526.0 1.175.0h13.65C15.474.0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487.0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837.0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822.0-1.359.54-1.359 1.248.0.694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869.0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274.0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54.0 01.016-.025V6.169h-2.4c.03.678.0 7.225.0 7.225h2.4z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Data Privacy; Disclosure control and differential privacy on reddit" href="https://reddit.com/submit?url=%2fposts%2f2021-08-05-disclosure_control_privacy%2f&title=Data%20Privacy%3b%20Disclosure%20control%20and%20differential%20privacy"><svg width="16" height="16" class="bi bi-reddit" viewBox="0 0 16 16"><path d="M6.167 8a.831.831.0 00-.83.83c0 .459.372.84.83.831a.831.831.0 000-1.661zm1.843 3.647c.315.0 1.403-.038 1.976-.611a.232.232.0 000-.306.213.213.0 00-.306.0c-.353.363-1.126.487-1.67.487-.545.0-1.308-.124-1.671-.487a.213.213.0 00-.306.0.213.213.0 000 .306c.564.563 1.652.61 1.977.61zm.992-2.807c0 .458.373.83.831.83s.83-.381.83-.83a.831.831.0 00-1.66.0z"/><path d="M16 8A8 8 0 110 8a8 8 0 0116 0zm-3.828-1.165c-.315.0-.602.124-.812.325-.801-.573-1.9-.945-3.121-.993l.534-2.501 1.738.372a.83.83.0 10.83-.869.83.83.0 00-.744.468l-1.938-.41a.203.203.0 00-.153.028.186.186.0 00-.086.134l-.592 2.788c-1.24.038-2.358.41-3.17.992-.21-.2-.496-.324-.81-.324A1.163 1.163.0 003.37 9.069c-.02.115-.029.23-.029.353.0 1.795 2.091 3.256 4.669 3.256 2.577.0 4.668-1.451 4.668-3.256.0-.114-.01-.238-.029-.353.401-.181.688-.592.688-1.069.0-.65-.525-1.165-1.165-1.165z"/></svg></a></li><li><a href="whatsapp://send?text=%2fposts%2f2021-08-05-disclosure_control_privacy%2f&amp;description=Data%20Privacy%3b%20Disclosure%20control%20and%20differential%20privacy" target=_blank rel=noopener title="Share on WhatsApp"><svg width="16" height="16" class="bi bi-whatsapp" viewBox="0 0 16 16"><path d="M13.601 2.326A7.854 7.854.0 007.994.0C3.627.0.068 3.558.064 7.926c0 1.399.366 2.76 1.057 3.965L0 16l4.204-1.102a7.933 7.933.0 003.79.965h.004c4.368.0 7.926-3.558 7.93-7.93A7.898 7.898.0 0013.6 2.326zM7.994 14.521a6.573 6.573.0 01-3.356-.92l-.24-.144-2.494.654.666-2.433-.156-.251A6.56 6.56.0 011.407 7.922c0-3.626 2.957-6.584 6.591-6.584a6.56 6.56.0 014.66 1.931 6.557 6.557.0 011.928 4.66c-.004 3.639-2.961 6.592-6.592 6.592zm3.615-4.934c-.197-.099-1.17-.578-1.353-.646-.182-.065-.315-.099-.445.099-.133.197-.513.646-.627.775-.114.133-.232.148-.43.05-.197-.1-.836-.308-1.592-.985-.59-.525-.985-1.175-1.103-1.372-.114-.198-.011-.304.088-.403.087-.088.197-.232.296-.346.1-.114.133-.198.198-.33.065-.134.034-.248-.015-.347-.05-.099-.445-1.076-.612-1.47-.16-.389-.323-.335-.445-.34-.114-.007-.247-.007-.38-.007a.729.729.0 00-.529.247c-.182.198-.691.677-.691 1.654.0.977.71 1.916.81 2.049.098.133 1.394 2.132 3.383 2.992.47.205.84.326 1.129.418.475.152.904.129 1.246.08.38-.058 1.171-.48 1.338-.943.164-.464.164-.86.114-.943-.049-.084-.182-.133-.38-.232z"/></svg></a></li></ul></div><p class=text-muted>It makes me smile, when I see it.</p></div></section></div><div class="col-lg-8 offset-lg-2 col-md-12 offset-md-1 pt-4"><ul class="list-group list-group-horizontal" style=flex-direction:row><li class="list-group-item b-0 p-0"><a type=button class="btn btn-dark" role=button href=/posts/2021-01-21_interactive_time_series/ data-toggle=tooltip data-placement=top title="Interactive time series plots">&larr;
Previous Post</a></li><li class="list-group-item ms-auto b-0 p-0"><a type=button class="btn btn-dark" role=button href=/posts/2024-05-23-post_office_horizon/ data-toggle=tooltip data-placement=top title="Reflections on the Post Office Horizon Enquiry">Next Post
&rarr;</a></li></ul></div><div class="col-lg-8 offset-lg-2 col-md-10 offset-md-1 pt-4"></div></div></div><div><div class=container><div class=row><div class="col-lg-12 col-md-12 mt-3"><h3>Read More</h3><hr></div><div class="col-xl-4 col-lg-4 col-md-6 col-sm-6 mb-4"><a href=/posts/2024-05-23-post_office_horizon/><div class="card h-100 single-post-card shadow-effect bg-faded-light border"><div class=card-body><h3 class="fw-medium post-title">Reflections on the Post Office Horizon Enquiry</h3><p class=post-meta><span class="post-meta text-muted">23 May 2024
&nbsp;|&nbsp; <i class="bi bi-clock"></i>&nbsp;2&nbsp;minutes
&nbsp;|&nbsp;<i class="bi bi-book"></i>&nbsp;369&nbsp;words</span></p><div class=post-entry>The role of data in governance</div><div class=read-more-section><h6 class="text-muted link-underline">Read More <i class="bi bi-arrow-right"></i></h6></div></div></div></a></div></div></div></div><footer><div class=container><div class=row><div class=col-md-12><ul class="list-inline list-group list-group-horizontal text-center footer-links d-flex justify-content-center flex-row"><li><a href=mailto:paul@insightsforaction.uk title="Email me" target=_blank><span class=mx-2><i class="bi bi-envelope"></i></span></a></li><li><a href=https://github.com/https://github.com/phewson title=GitHub target=_blank><span class=mx-2><i class="bi bi-github"></i></span></a></li><li><a href=https://linkedin.com/in/https://www.linkedin.com/in/pahewson/ title=LinkedIn target=_blank><span class=mx-2><i class="bi bi-linkedin"></i></span></a></li><li><a href=https://www.youtube.com/@PaulHewsonPhD title=Youtube target=_blank><span class=mx-2><i class="bi bi-youtube"></i></span></a></li><li><a href=https://https://datasci.social/@texhewson title=Mastodon target=_blank><span class=mx-2><i class="bi bi-mastodon"></i></span></a></li></ul></div></div><div class=row><div class=col-md-12><p class="credits copyright text-muted"><a href=https://insightsforaction.uk>Paul Hewson</a>
&nbsp;&bull;&nbsp;&copy;
2025
&nbsp;&bull;&nbsp;
<a href=/>Insights for Action</a></p><p class="credits theme-by text-muted">Powered by <a href=https://gohugo.io>Hugo</a> & <a href=https://github.com/binokochumolvarghese/lightbi-hugo>Lightbi.</a>&nbsp; Made with ❤ by <a href=https://binovarghese.com>Bino</a></p></div></div></div></footer><script src=/vendor/bootstrap/js/bootstrap.bundle.min.js></script><script src=/js/highlight.min.js></script><script>hljs.initHighlightingOnLoad()</script><script>document.addEventListener("DOMContentLoaded",function(){document.querySelectorAll("pre.chroma").forEach(function(e){e.style.padding="0"})})</script></body></html>